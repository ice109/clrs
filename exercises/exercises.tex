%% LyX 2.1.4 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[oneside,english]{amsart}
\usepackage{lmodern}
\renewcommand{\sfdefault}{lmss}
\renewcommand{\ttdefault}{lmtt}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage[letterpaper]{geometry}
\geometry{verbose,tmargin=2cm,bmargin=2cm}
\setcounter{secnumdepth}{5}
\setcounter{tocdepth}{5}
\setlength{\parskip}{\medskipamount}
\setlength{\parindent}{0pt}
\usepackage{color}
\usepackage{babel}
\usepackage{float}
\usepackage{amstext}
\usepackage{amsthm}
\usepackage[unicode=true,pdfusetitle,
 bookmarks=true,bookmarksnumbered=false,bookmarksopen=false,
 breaklinks=false,pdfborder={0 0 1},backref=false,colorlinks=true]
 {hyperref}

\makeatletter
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
\numberwithin{equation}{section}
\numberwithin{figure}{section}
  \theoremstyle{definition}
  \newtheorem*{xca*}{\protect\exercisename}
  \theoremstyle{definition}
  \newtheorem*{problem*}{\protect\problemname}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
\usepackage{tikz}
\usepackage{graphicx}
\usetikzlibrary{shapes.multipart}
\usetikzlibrary{decorations.pathreplacing}
\usepackage{xparse}% http://ctan.org/pkg/xparse
\usepackage{parskip}

\makeatother

\usepackage{listings}
  \providecommand{\exercisename}{Exercise}
  \providecommand{\problemname}{Problem}
\renewcommand{\lstlistingname}{Listing}

\begin{document}
\tableofcontents{}


\part*{Note}

\textbf{I have variously stolen, plagiarized, copied, etc. from many
places. Rarely I cite. This is out of pure laziness on my part. For
the sake of intellectual honesty consider that absolutely none of
this is my own work (it's simply a collection). }Maybe eventually
I'll go back and cite but probably not.

Everything is $1$ indexed, despite using vaguely Pythonic syntax.
This means $A\left[\text{len}\left(A\right)\right]=A\left[-1\right]$.
Slicing is $A\left[a:b\right]=\left[A_{a},A_{a+1},\dots,A_{b-1}\right]$. 

Where bounds checking is obviously necessary it is omitted. I assume
a different memory model from Python: each entry of $B=\left[\left[\right]\right]$
is an independent list. 

Ranges are represented using MATLAB notation $1:n$. 

In certain places I play fast and loose with what a dictionary is
keyed on and whether a label is just a label or a pointer (in particular
in the Graph Algorithms section). Also I iterate over a dictionary,
which is possible with python's \texttt{dict.items}$\left(\right)$.

The layout has large gaps intentionally. This is so pictures and diagrams
follow their introductions/allusions/references in the text. That
means if a picture/diagram is introduced and isn't on the page then
it leads on the following page.


\part{Foundations}

\addtocounter{section}{3}


\section{Divide-and-Conquer}
\begin{xca*}
[4.1-5]\addcontentsline{toc}{subsection}{\numberline{}Exercise 4.1-5}Given
$A=\left[a_{1},\dots,a_{n}\right]$, how to find the subarray with
the maximum positive sum? Write a linear-time, nonrecursive algorithm
for the maximum-subarray problem.
\end{xca*}
Kidane's algorithm: change the problem to look at maximum sum subarray
ending at some $j$. Maximum sum subarray ending at $j$ is either
empty, i.e. has negative sum, in which case its sum is 0, or includes
$A\left[j\right]$. The maximum sum subarray in all of $A$ is the
maximum of all subarrays ending at all $j$. Running time is $\Theta\left(n\right)$.

\begin{figure}[H]
\begin{lstlisting}[language=Python,numbers=left,basicstyle={\ttfamily},showstringspaces=false,tabsize=3,mathescape=true,frame=single,xleftmargin={.2\textwidth},xrightmargin={.2\textwidth}]
Kidane-Max-Subarray$\left(A\right)$
	# $m$_  is max
	$m_{here} = m_{all} = A\left[1\right]$
	for $i=2:\text{len}\left(A\right)$: 
		$m_{here} = \max\left(0,m_{here}+A\left[i\right]\right)$
		$m_{all} = \max\left(m_{all},m_{here}\right)$
	return $m_{all}$
\end{lstlisting}
\end{figure}
Note that if at $j-1$ the subarray was empty, and hence $m_{here}=0$
then at $j$ it's the case that $m_{here}=A\left[j\right]$. In order
to recover the actual subarray you need to keep track of whether counting
is reset or subarray is extended. Easiest way to do this is using
Python tricks. In general this is calling keeping ``back-pointers''
and works in all such cases for reconstructing the solution (forthwith
omitted).
\begin{figure}[H]
\begin{lstlisting}[language=Python,numbers=left,basicstyle={\ttfamily},showstringspaces=false,tabsize=3,mathescape=true,frame=single,xleftmargin={.001\textwidth},xrightmargin={.001\textwidth}]
Kidane-Max-Subarray-Mod$\left(A\right)$
	$m_{here} = m_{all} = \left[[~],A\left[1\right]\right]$
	for $i=2:\text{len}\left(A\right)$: 
		# take max wrt. first entry of arguments, i.e. $\max\left(0,m_{here}+A\left[i\right]\right)$
		$m_{here}=\max\left(\left[0,[~]\right],\left[m_{here}+A\left[i\right],m_{here}\text{.append}\left(A\left[i\right]\right)\right] ,\text{key=itemgetter}\left(1\right)\right)$
		$m_{all} = \max\left(m_{all},m_{here},\text{key=itemgetter}\left(1\right)\right)$
	return $m_{all}$
\end{lstlisting}
\end{figure}

\begin{problem*}
[4-4] \addcontentsline{toc}{subsection}{\numberline{}Problem 4-4}Fibonacci
numbers. Given the generating function for Fibonacci numbers 
\[
\mathcal{F}\left(z\right)=\sum_{i=0}^{\infty}F_{i}z^{i}
\]
where $F_{i}$ is the $i$th Fibonacci number
\begin{enumerate}
\item [(a)]Show that $\mathcal{F}\left(z\right)=z+z\mathcal{F}\left(z\right)+z^{2}\mathcal{F}\left(z\right)$.\\



\textbf{Solution}. Let $\mathcal{F}\left(z\right)=\left(0,1,1,2,3,5,8,13,\dots\right)$
the coefficients of the terms. Then multiplication by $z$
\[
z\mathcal{F}\left(z\right)=\left(0,0,1,1,2,3,5,8,\dots\right)
\]
and
\[
z^{2}\mathcal{F}\left(z\right)=\left(0,0,0,1,1,2,3,5,\dots\right)
\]
Hence 
\begin{alignat*}{2}
\quad z & = & \left(0,1,0,0,0,0,0,0,\dots\right)\;\\
\quad z\mathcal{F}\left(z\right) & = & \left(0,0,1,1,2,3,5,8,\dots\right)\;\\
\underline{+z^{2}\mathcal{F}\left(z\right)} & = & \left(0,0,0,1,1,2,3,5,\dots\right)\;\\
\quad\mathcal{F}\left(z\right) & = & \quad\left(0,1,1,2,3,5,8,13,\dots\right)
\end{alignat*}
\\


\item [(b)]Show that 
\[
\mathcal{F}\left(z\right)=\frac{1}{\sqrt{5}}\left(\frac{1}{1-\phi z}-\frac{1}{1-\hat{\phi}z}\right)
\]
where $\phi=\frac{1+\sqrt{5}}{2}$ and $\hat{\phi}=\frac{1-\sqrt{5}}{2}$.


\textbf{Solution}. Since
\[
F\left(z\right)=z+zF\left(z\right)+z^{2}F\left(z\right)
\]
we have that 
\[
F\left(z\right)\left(1-z-z^{2}\right)=z
\]
or
\[
F\left(z\right)=\frac{z}{1-z-z^{2}}
\]
Factoring the denominator
\begin{eqnarray*}
F\left(z\right) & = & \frac{z}{-\left(z+\frac{\left(1-\sqrt{5}\right)}{2}\right)\left(z+\frac{1+\sqrt{5}}{2}\right)}\\
 & = & \frac{z}{\left(1-z\left(\frac{1+\sqrt{5}}{2}\right)\right)\left(1-z\left(\frac{1-\sqrt{5}}{2}\right)\right)}\\
 & = & \frac{z}{\left(1-\phi z\right)\left(1-\hat{\phi}z\right)}\\
 & = & \frac{1}{\sqrt{5}}\left(\frac{1}{\left(1-\phi z\right)}-\frac{1}{\left(1-\hat{\phi}z\right)}\right)
\end{eqnarray*}


\item [(c)]Show that 
\[
\mathcal{F}\left(z\right)=\sum_{i=0}^{\infty}\frac{1}{\sqrt{5}}\left(\phi^{i}-\left(\hat{\phi}\right)^{i}\right)z^{i}
\]



\textbf{Solution}. Using the Taylor series 
\[
\frac{1}{1-x}=\sum_{n=0}^{\infty}x^{n}
\]
we have by above
\begin{eqnarray*}
F\left(z\right) & = & \frac{1}{\sqrt{5}}\left(\frac{1}{\left(1-\phi z\right)}-\frac{1}{\left(1-\hat{\phi}z\right)}\right)\\
 & = & \frac{1}{\sqrt{5}}\left(\sum_{n=0}^{\infty}\left(\phi z\right)^{n}-\sum_{n=0}^{\infty}\left(\hat{\phi}z\right)^{n}\right)\\
 & = & \sum_{n=0}^{\infty}\frac{1}{\sqrt{5}}\left(\phi^{n}-\hat{\phi}^{n}\right)z^{n}
\end{eqnarray*}


\item [(d)]Use part (c) to prove that $\left\{ F_{i}\right\} =\phi^{i}/\sqrt{5}$,
where $\left\{ \right\} $ is rounding to the nearest integer.


\textbf{Solution}. By comparing coefficients in the the original generating
function and the re-expression
\[
F\left(z\right)=\sum_{n=0}^{\infty}F_{n}z^{n}=\sum_{n=0}^{\infty}\frac{1}{\sqrt{5}}\left(\phi^{n}-\hat{\phi}^{n}\right)z^{n}
\]
we see that 
\[
F_{n}=\frac{1}{\sqrt{5}}\left(\phi^{n}-\hat{\phi}^{n}\right)
\]
Since $\left|\hat{\phi}\right|<1$ it's the case that $\left|\hat{\phi}^{n}\right|<1$
and hence is fractional.

\end{enumerate}
\end{problem*}

\begin{problem*}
[4-5] \addcontentsline{toc}{subsection}{\numberline{}Problem 4-5}Chip
testing.
\begin{enumerate}
\item [(a)]Show that if more than $n/2$ chips are bad, the professor cannot
necessarily determine which chips are good using any strategy based
on this kind of pairwise test. Assume that the bad chips can conspire
to fool the professor.


\textbf{Solution}. Let $g$ be the number of good chips and $n-g\geq g$
be the number of bad chips. Then there exists a set of good chips
$G$ and a set of bad chips $B$ such that $\left|G\right|=\left|B\right|$.
The bad chips can conspire to fool the professor in the following
way: they call themselves good and the actually good chips bad. The
good chips of course report exactly antisymmetrically that they're
good and the bad chips are bad. Therefore these two sets of chips
are indistinguishable.

\item [(b)]Consider the problem of finding a single good chip from among
$n$ chips, assuming that more than $n/2$ of the chips are good.
Show that $\left\lfloor n/2\right\rfloor $ pairwise tests are sufficient
to reduce the problem to one of nearly half the size.


\textbf{Solution}. Note that if a test is $\left(\mbox{good},\mbox{good}\right)$
then either both chips are bad or both good. Otherwise at least one
is bad. Here's the Divide-and-Conquer algorithm:
\begin{enumerate}
\item [(1)]If there's only one chip, then it must be good.
\item [(2)]Split the chips into two-chip pairs. If the number of chips
is odd let $c$ denote the odd one out.
\item [(3)]Test each pair. If the result if $\left(\mbox{good},\mbox{good}\right)$,
then throw one away, otherwise throw away both.
\item [(4)]Repeat.
\end{enumerate}

The algorithm performs $\left\lfloor n/2\right\rfloor $ pairwise
tests, and keeps at most $\left\lceil n/2\right\rceil $ chips. Now
to show that at least half of the remaining chips are good each time:
at a particular iteration, assume $x$ pairs consist of two good chips,
$y$ pairs are mixed, $z$ pairs consist of bad chips. Then there
are possibilities:
\begin{itemize}
\item If $n$ is even, then $g=2x+y\geq y+2z=b$ and $x\geq y$ implies
more at least as many good chips as bad chips remain.
\item If $n$ is odd, and $c$ is bad then $g=2x+y\geq y+2z+1=b$ and $x\geq z+1$
(since $x,z$ are integers). Since in fact $x$ good chips and $z+1$
bad chips remain, it is the case that more good chips than bad chips
remain.
\item If $n$ is odd, and $c$ is good then $g=2x+y+1\geq y+2z=b$ and $x+1\geq z$
(since $x,z$ are integers). Since in fact $x+1$ good chips and $z$
bad chips remain, it is the case that more good chips than bad chips
remain.
\end{itemize}

Therefore more good chips than bad chips remain always.

\item [(c)]Show that the good chips can be identified with $\Theta\left(n\right)$
pairwise tests, assuming that more than $n/2$ of the chips are good.
Give and solve the recurrence that describes the number of tests.


\textbf{Solution}. Use the result of (b) to find a good chip in $\Theta\left(\lg n\right)$
time and then use it to perform the other $n-1$ comparisons.

\end{enumerate}
\end{problem*}

\begin{problem*}
[4-6] \addcontentsline{toc}{subsection}{\numberline{}Problem 4-6}Monge
arrays.
\begin{enumerate}
\item [(a)]Prove that an array is Monge iff for all $i=1,\dots m-1$ and
$j=1,\dots,n-1$ we have that 
\[
A\left[i,j\right]+A\left[i+1,j+1\right]\leq A\left[i,j+1\right]+A\left[i+1,j\right]
\]



\textbf{Solution}. If an array is Monge then it the property holds
by defintion. Conversely suppose an $m\times n$ array has the property.
We prove that 
\[
A\left[i,j\right]+A\left[i+x,j+y\right]\leq A\left[i,j+y\right]+A\left[i+x,j\right]
\]
for all $x,y$ such that $1\leq x\leq m-1$ and $1\leq y\leq n-j$,
i.e. the array is Monge. For $x=y=1$ the property holds by assumption.
First suppose $x'<m$ and $y'\leq n$ and the property holds for all
$x,y$ such that $1\leq x\leq x'$ and $1\leq y\leq y'$. Then it
holds for $x=x'+1$ and $y='y$: consider $i<m-x'$ and $j\leq n-y'$.
By assumption we have that
\[
A\left[i,j\right]+A\left[i+x',j+y'\right]\leq A\left[i,j+y'\right]+A\left[i+x',j\right]
\]
and
\[
A\left[i+x',j\right]+A\left[i+x'+1,j+y'\right]\leq A\left[i+x',j+y'\right]+A\left[i+x'+1,j\right]
\]
Summing these two implies
\[
A\left[i,j\right]+A\left[i+x'+1,j+y'\right]\leq A\left[i,j+y'\right]+A\left[i+x'+1,j\right]
\]
Similarly we can argue the case for $x'\leq m$ and $y'<n$ and thus
it holds for $x=x'$ and $y=y'+1$.

\item [(c)]Let $f\left(i\right)$ be the index of the column containing
the leftmost minimum element of row $i$. Prove that $f\left(1\right)\leq f\left(2\right)\leq\cdots\leq f\left(m\right)$
for any $m\times n$ Monge array.


\textbf{Solution}. By contradiction: assume the inequality is false.
Then there is some $i$ such that $f\left(i\right)>f\left(i+1\right)$
such that $A\left[i,f\left(i+1\right)\right]>A\left[i,f\left(i\right)\right]$.
Then
\[
A\left[i,f\left(i+1\right)\right]+A\left[i+1,f\left(i\right)\right]>A\left[i,f\left(i\right)\right]+A\left[i+1,f\left(i+1\right)\right]
\]
a contradiction.

\item [(d)]Here is a description of a divide-and-conquer algorithm that
computes the left- most minimum element in each row of an $m\times n$
Monge array $A$: Construct a submatrix $A'$ of $A$ consisting of
the even-numbered rows of $A$. Recursively determine the leftmost
minimum for each row of $A'$. Then compute the leftmost minimum in
the odd-numbered rows of $A$.


Explain how to compute the leftmost minimum in the odd-numbered rows
of A (given that the leftmost minimum, and its index, of the even-numbered
rows is known) in $O\left(m+n\right)$ time.


\textbf{Solution}. Using part (c), if we know the minimum elements
$f\left(i\right)$ for the even rows then for each odd $2i+1$ row
we only need to check columns between $f\left(2i\right)$ and $f\left(2i+2\right)$.
Hence we can compute the minima of the odd rows in time 
\[
\sum_{i=1}^{m/2}f\left(2i+2\right)-f\left(2i\right)+1=O\left(m+n\right)
\]


\item [(e)]Write the recurrence describing the running time of the algorithm
described in part (d). Show that its solution is $O\left(m+n\lg m\right)$.


\textbf{Solution}. The recurrence is 
\begin{eqnarray*}
T\left(m\right) & = & T\left(m/2\right)+O\left(m+n\right)\\
 & = & O\left(\sum_{k=0}^{\lg m}\left(\frac{m}{2^{k}}+n\right)\right)\\
 & = & O\left(m+n\lg m\right)
\end{eqnarray*}


\end{enumerate}
\end{problem*}
\addtocounter{section}{1}


\part{Sorting and Order Statistics}


\section{Heapsort}
\begin{xca*}
[6.5-7]\addcontentsline{toc}{subsection}{\numberline{}Exercise 6.5-7}
Show how to implement a first-in, first-out queue with a priority
queue. Show how to implement a stack with a priority queue.
\end{xca*}
\textbf{Solution}. Run a timer. To construct a FIFO make the priority
key the insertion time. To construct a LIFO make the priority key
$1/\mbox{insertion time}$.


\begin{xca*}
[6.5-9]\addcontentsline{toc}{subsection}{\numberline{}Exercise 6.5-9}
Give an $O\left(n\lg k\right)$ algorithm for constructing a sorted
array from $k$ already sorted arrays (where the total number of elements
is $n$).
\end{xca*}
\textbf{Solution}. Use a MinHeap with the extract min property: construct
a MinHeap from first elements in each array. Pop the the minimum element
and add to a surrogate array. Replace with the next element of the
array that that one came from. This way the smallast element of each
of the $k$ arrays is always in direct competition. Constructing the
initial array is $O\left(k\right)$ and then each of the Extract-min
operations costs $\lg k$, hence $O\left(n\lg k\right)$.


\begin{problem*}
[6-3]\addcontentsline{toc}{subsection}{\numberline{}Problem 6-3}
Young tableuax.
\begin{enumerate}
\item [(c)]Give an algorithm to implement $\texttt{Extract-Min}$ on a
nonempty $m\times n$ Young tableau that runs in $O\left(m+n\right)$
time.


\textbf{Solution}. $Y\left[1,1\right]$ is clearly the minimum. Pop
it and replace it with the bottom right element, then ``percolate
down''.

\item [(d)]Show how to insert a new element into a nonfull $m\times n$
Young tableau in $O\left(m+n\right)$ time.


\textbf{Solution}. Insert at the bottom right, then ``percoluate
up''.

\item [(e)]Using no other sorting method as a subroutine, show how to use
an $n\times n$ Young tableau to sort $n^{2}$ numbers in $O\left(n^{3}\right)$
time.


\textbf{Solution}. Repeatedly $\texttt{Extract-Min}$.

\item [(f)]Give an $O\left(m+n\right)$-time algorithm to determine whether
a given number is stored in a given $m\times n$ Young tableau.


\textbf{Solution}. Start at the top right, then you know everything
below you is greater and everything to the left is smaller. If the
number you're looking for is smaller than the current entry then go
left, and if the number is greater than the current entry then go
down.

\end{enumerate}
\end{problem*}

\section{Quicksort}


\begin{problem*}
[7-6]\addcontentsline{toc}{subsection}{\numberline{}Problem 7-6}
Fuzzy sorting of intervals.
\begin{enumerate}
\item [(a)]Design a randomized algorithm for fuzzy-sorting n intervals.
Your algorithm should have the general structure of an algorithm that
quicksorts the left endpoints (the $a_{i}$ values), but it should
take advantage of overlapping intervals to improve the running time.
(As the intervals overlap more and more, the problem of fuzzy-sorting
the intervals becomes progressively easier. Your algorithm should
take advantage of such overlapping, to the extent that it exists.).


\textbf{Solution}. The key is that two intervals intersect (overlap)
then they don't need to be sorted. That's where the speedup comes
from. To that end here's code to compute the intersection (if any
exists) of a set $I=\left(\left(a_{1},b_{1}\right),\dots,\left(a_{n},b_{n}\right)\right)$
of intervals


\begin{lstlisting}[language=Python,numbers=left,basicstyle={\ttfamily},showstringspaces=false,tabsize=3,mathescape=true,frame=single,xleftmargin={.2\textwidth},xrightmargin={.2\textwidth}]
Intersection$\left(I\right)$
	$ i = \text{random}\left(\right)$
	$I\left[-1\right],I\left[i\right]=I\left[i\right],I\left[-1\right]$
	$a,b = I\left[-1\right]\left[1\right], I\left[-1\right]\left[2\right]$
	for $i=1:\text{len}\left(I\right)-1$: 
		if $a\leq I\left[i\right]\left[1\right]\leq b$ or $a\leq I\left[i\right]\left[2\right]\leq b$:
			if $ a< I\left[i\right]\left[1\right]$:
				$a = I\left[i\right]\left[1\right]$
			if $ B\left[i\right] < b$:
				$b = I\left[i\right]\left[2\right]$
	return $a,b$
\end{lstlisting}



This computes the intersection of all intervals if one exists; it
does not find one! Note that $a\leq I\left[i\right]\left[1\right]\leq b\text{ or }a\leq I\left[i\right]\left[2\right]\leq b$
can be simplified down to $I\left[i\right]\left[1\right]\leq b\,\wedge I\left[i\right]\left[1\right]\geq a$,
since $a_{i}\leq b_{i}$. Running time is clearly $\Theta\left(n\right)$.


Now using the model of $\texttt{Quicksort}$ we can build a $\texttt{Fuzzy-sort}$:
partition the input array into ``left'',''middle'', and ``right''
subarrays, where the ``middle'' subarray contains intervals that
overlap the intersection of all of them {[}the intervals{]} and don't
need to be sorted any further. Running time is $O\left(n\lg n\right)$
in general but if all of the intervals overlap then the recursion
returns without executing anything and so only the $\texttt{filter}$s
run (which are $O\left(n\right)$).


\begin{lstlisting}[language=Python,numbers=left,basicstyle={\ttfamily},showstringspaces=false,tabsize=3,mathescape=true,frame=single,xleftmargin={.01\textwidth},xrightmargin={.01\textwidth}]
Fuzzy-Sort$\left(I\right)$
	if len$\left(I\right)\leq 1$:
		return $I$
	else:
		$a,b = \text{Intersection}\left(A,B\right)$
		# first partition for similar reasons to Quicksort,
		# in order to actually sort, i.e. everything in $I_{right}$
		# follows everything in $I_{left}$ in the final ordering
		# but use $a$ as the pivot in order for the second 
		# partition to be effective
		$I_{left} = \text{filter}\left(I,\lambda i: i\left[1\right]\leq a\right)$
		$I_{right} =\text{filter}\left(I,\lambda i: i\left[1\right] > a\right)$
		# find all the intervals in $I_{left}$ that overlap $\left[a,b\right]$, but 
		# since $\left[a,b\right]$ is an intersection it should be 
		# contained in these intervals
		# therefore everything in $I_{middle}$ is such that $ \left[a,b\right]\subseteq \left[a_i,b_i\right]$
		$I_{middle} = \text{filter}\left(I,\lambda i:   b \leq i\left[2\right]\right)$
		# and $I_{left-left}$ is everything else.
		$I_{left-left} = \text{filter}\left(I,\lambda i: i\left[2\right] < b\right)$
		return $\text{Fuzzy-Sort}\left(I_{left-left}\right) + I_{middle} + \text{Fuzzy-Sort}\left(I_{right}\right)$
\end{lstlisting}


\end{enumerate}
\end{problem*}

\section{Sorting in Linear Time}
\begin{xca*}
[8.2-4]\addcontentsline{toc}{subsection}{\numberline{}Exercise 8.2-4}
Describe an algorithm that, given $n$ integers in the range $0$
to $k$, preprocesses its input and then answers any query about how
many of the $n$ integers fall into a range $\left[a\dots b\right]$
in $O\left(1\right)$ time. Your algorithm should use $\Theta\left(n+k\right)$
preprocessing time.
\end{xca*}
\textbf{Solution}. Suppose the the cumulates array constructed by
$\texttt{Counting-Sort}$ is $C$. Then $C\left[b\right]-C\left[a\right]$
is the answer to the query.


\begin{xca*}
[8.3-4]\addcontentsline{toc}{subsection}{\numberline{}Exercise 8.3-4}
Show how to sort $n$ integers in the range 0 to $n^{3}$-1 in $O\left(n\right)$
time.
\end{xca*}
\textbf{Solution}. $n$ base $n$ the number $n^{3}-1$ are two digits
numbers e.g. $1000_{n}=1\times n^{3}+0n^{2}+0n+0\times1$. So we make
4 passes using radix sort
\[
\Theta\left(4\left(n+n\right)\right)=O\left(n\right)
\]



\begin{xca*}
[8.4-4]\addcontentsline{toc}{subsection}{\numberline{}Exercise 8.4-4}
We are given n points in the unit circle, $p_{i}=\left(x_{i},y_{i}\right)$,
such that $0<x_{i}^{2}+y_{i}^{2}\leq1$ for $i=1,\dots,n$. Suppose
that the points are uniformly distributed; that is, the probability
of finding a point in any region of the circle is proportional to
the area of that region. Design an algorithm with an average-case
running time of $\Theta\left(n\right)$ to sort the $n$ points by
their distances $d_{i}=\sqrt{x_{i}^{2}+y_{i}^{2}}$ from the origin.
\end{xca*}
\textbf{Solution}. A differential ring of area on the unit circle
is $dA=2\pi rdr$ so using bucket sort we can divide up the buckets
according this scaling.


\begin{xca*}
[8.4-5]\addcontentsline{toc}{subsection}{\numberline{}Exercise 8.4-5}
Suppose that we draw a list of $n$ random variables $X_{1},\dots,X_{n}$
from a continuous probability distribution function $P$ that is computable
in $O\left(1\right)$ time. Give an algorithm that sorts these numbers
in linear average-case time.
\end{xca*}
\textbf{Solution}. $Y=P\left(X_{i}\right)$ is uniformly distributed.
\begin{problem*}
[8-5]\addcontentsline{toc}{subsection}{\numberline{}Problem 8-5}
Jugs.
\begin{enumerate}
\item [(a)]Describe a deterministic algorithm that uses $\Theta\left(n^{2}\right)$
comparisons to group the jugs into pairs.


\textbf{Solution}. Test every blue jug against every red jug.

\item [(b)]Skip.
\item [(c)]Show how to match the jugs in $O\left(n\lg n\right)$ time.


\textbf{Solution}. You could match up the jugs by sorting each set
and lining them up. Too bad you can't compare red jugs against red
jugs right? But you can just use the $\texttt{Quicksort}$ model and
with blue jugs being pivots for red jugs and red jugs being pivots
for blue jugs.

\end{enumerate}
\end{problem*}

\section{Medians and Order Statistics}
\begin{xca*}
[9.1-1]\addcontentsline{toc}{subsection}{\numberline{}Exercise 9.1-1}
Show that the second smallest of $n$ elements can be found with $n+\left\lceil \lg n\right\rceil -2$
comparisons in the worst case. 
\end{xca*}
\textbf{Solution}. Tournament style to determine minimum: comparing
all pairs costs $n/2$, compare all winners of the first round costs
$n/4$, etc. In total this is $n-1$ comparisons. The only way in
which the second smallest element is not in the final round is it
was eliminated in an earlier round. Therefore keep track of all of
the elements that the smallest element ``played'' against, which
is $\left\lceil \lg n\right\rceil $, and find the smallest of them.
This costs $\left\lceil \lg n\right\rceil -1$ comparisons.


\begin{xca*}
[9.3-5]\addcontentsline{toc}{subsection}{\numberline{}Exercise 9.3-5}
Suppose that you have a \textquotedblleft black-box\textquotedblright{}
worst-case linear-time median subroutine. Give a simple, linear-time
algorithm that solves the selection problem for an arbitrary order
statistic.
\end{xca*}
\textbf{Solution}. Suppose the rank you're looking for is $r$ and
the number of elements is $n$. Use binary search: find the median,
then if the order statistic is higher than the median find the $r-\left\lfloor n/2\right\rfloor $
order statistic of the elements larger than the median, and if the
order statistic is lower then find the rank $r$ statistic of the
elements smaller than the median, and so on.


\begin{xca*}
[9.3-6]\addcontentsline{toc}{subsection}{\numberline{}Exercise 9.3-6}
The $k$th quantiles of an $n$-element set are the $k-1$ order statistics
that divide the sorted set into $k$ equal-sized sets (to within 1).
Give an $O\left(n\lg k\right)$-time algorithm to list the $k$th
quantiles of a set.
\end{xca*}
\textbf{Solution}. If $k$ is even then there are $k-1$ (an odd number)
of ``pivots'' and one of them is the median. Find the median, partition,
then solve the subproblems. If $k$ is odd do the same thing but be
more careful.


\begin{xca*}
[9.3-7]\addcontentsline{toc}{subsection}{\numberline{}Exercise 9.3-7}Describe
an $O\left(n\right)$-time algorithm that, given a set $S$ of $n$
distinct numbers and a positive integer $k\leq n$, determines the
$k$ numbers in $S$ that are closest to the median of $S$.
\end{xca*}
\textbf{Solution}. Find the median, then subtract the median from
every element, then find the $k$th order statistic (and in doing
so partition).


\begin{xca*}
[9.3-8]\addcontentsline{toc}{subsection}{\numberline{}Exercise 9.3-8}Let
$X\left[1\dots n\right]$ and $Y\left[1\dots n\right]$ be two arrays,
each containing $n$ numbers already in sorted order. Give an $O\left(\lg n\right)$-time
algorithm to find the median of all $2n$ elements in arrays $X$
and $Y$.
\end{xca*}
\textbf{Solution}. The median all of $2n$ elements is always in between
the median of each array (by value). Compute the medians in $O\left(1\right)$
time. If they're equal return them. Otherwise recurse to either the
leftside or rightside of each array depending on which median is larger
than which.


\begin{xca*}
[9.3-9]\addcontentsline{toc}{subsection}{\numberline{}Exercise 9.3-9}Given
the $x$- and $y$-coordinates of the wells, how should the professor
pick the optimal location of the main pipeline, which would be the
one that minimizes the total length of the spurs? Show how to determine
the optimal location in linear time.
\end{xca*}
\textbf{Solution}. The median is the element that minimizes the $L_{1}$
norm, i.e. the sum of distances.
\begin{problem*}
[9-2]\addcontentsline{toc}{subsection}{\numberline{}Problem 9-2}
Weighted median.
\begin{enumerate}
\item [(a)]Argue that the median of $x_{1},\dots,x_{n}$ is the weighted
median of the $x_{i}$ with weights $w_{i}=1/n$ for $i=1,\dots,n$.


\textbf{Solution}. This is trivially true (algebraically).

\item [(b)]Show how to compute the weighted median of $n$ elements in
$O\left(n\lg n\right)$ worst-case time using sorting.


\textbf{Solution}. Sort then sum weights, in order of increasing elements,
until you exceed $1/2$.

\item [(c)]Show how to compute the weighted median in $\Theta\left(n\right)$
worst-case time using a linear-time median algorithm such as $\texttt{SELECT}$
from Section 9.3.


\textbf{Solutio n}. Call $t=1/2$ the target. Find the median (and
in doing so partition around it) and compute the sum of the weights
in the ``lower'' half. If they sum to $t$ then return the median.
If the exceed then compute the median in the ``lower'' half. If
the sum is less than $t$ then compute the median in the ``top half''
but with target being $t$ minus the sum you just computed.

\item [(d)]Argue that the weighted median is a best solution for the 1-dimensional
post- office location problem, in which points are simply real numbers
and the dis- tance between points $a$ and $b$ is $d\left(a,b\right)=\left|a-b\right|$.


\textbf{Solution}. This is true for the same reason the median minimizes
the $L_{1}$ norm.

\item [(e)]Find the best solution for the 2-dimensional post-office location
problem, in which the points are $\left(x,y\right)$ coordinate pairs
and the distance between points $a=\left(x_{1},y_{,1}\right)$ and
$b=\left(x_{2},y_{2}\right)$ is the Manhattan distance given by $d\left(a,b\right)=\left|x_{1}-x_{2}\right|+\left|y_{1}-y_{2}\right|$.


\textbf{Solution}. Since the components of the distance ``vector''
are decoupled you can just do median in each coordinate, i.e. take
the median of all of the $x_{i}$ and the median of all of the $y_{i}$.

\end{enumerate}
\end{problem*}

\section{Elementary Data Structures}
\begin{xca*}
[10.1-2]\addcontentsline{toc}{subsection}{\numberline{}Exercise 10.1-2}
Explain how to implement two stacks in one array $A\left[1\dots n\right]$
in such a way that neither stack overflows unless the total number
of elements in both stacks together is $n$. The $\texttt{PUSH}$
and $\texttt{POP}$ operations should run in $O\left(1\right)$ time.
\end{xca*}
\textbf{Solution}. Have one stack grow from the left side of the array
and the other stack from the right side of the array (store their
ends). When they collide then they're both ``full''.


\begin{xca*}
[10.1-5]\addcontentsline{toc}{subsection}{\numberline{}Exercise 10.1-5}
Whereas a stack allows insertion and deletion of elements at only
one end, and a queue allows insertion at one end and deletion at the
other end, a deque (double-ended queue) allows insertion and deletion
at both ends. Write four $O\left(1\right)$-time procedures to insert
elements into and delete elements from both ends of a deque implemented
by an array.
\end{xca*}
\textbf{Solution}. Either use a circular list with the head and tail
linked or an array using mod to update indices that keep track of
the back and front and checking for collision of the indices.


\begin{xca*}
[10.1-6]\addcontentsline{toc}{subsection}{\numberline{}Exercise 10.1-6}
Show how to implement a queue using two stacks. Analyze the running
time of the queue operations.
\end{xca*}
\textbf{Solution}. Call the two stacks ``inbox'' and ``outbox''.
Push to one stack and pop from the other. If the \textquotedbl{}outbox\textquotedbl{}
stack is empty then pop everything from the inbox stack and push to
outbox stack. They'll be pushed in reverse order and pops will produce
the correct behavior. Amortized time is $O\left(n\right)$.


\begin{xca*}
[10.1-7]\addcontentsline{toc}{subsection}{\numberline{}Exercise 10.1-7}
Show how to implement a stack using two queues. Analyze the running
time of the stack operations.
\end{xca*}
\textbf{Solution}. Exactly like 10.1-6.


\begin{xca*}
[10.4-2]\addcontentsline{toc}{subsection}{\numberline{}Exercise 10.4-2}
Write an $O\left(n\right)$-time recursive procedure that, given an
$n$-node binary tree, prints out the key of each node in the tree.
\end{xca*}
\textbf{Solution}. DFS (or BFS).


\begin{xca*}
[10.4-3]\addcontentsline{toc}{subsection}{\numberline{}Exercise 10.4-3}
Write an $O\left(n\right)$-time nonrecursive procedure that, given
an $n$-node binary tree, prints out the key of each node in the tree.
Use a stack as an auxiliary data structure.
\end{xca*}
\textbf{Solution}. This is of course DFS but written iteratively.
Assume the tree is represented by a $\texttt{dict}\left(\right)$
with $\texttt{'leftchild'}$ and $\texttt{'rightchild'}$ keys (whose
corresponding values are the nodes). Since we're traversing a tree
we don't need to check for backpointers (i.e. don't need to mark visited).

\begin{lstlisting}[language=Python,numbers=left,basicstyle={\ttfamily},showstringspaces=false,tabsize=3,mathescape=true,frame=single,xleftmargin={.2\textwidth},xrightmargin={.2\textwidth}]
DFS$\left(T\right)$
	$stk = \left[T\right]$
	while len$\left(stk\right) > 0$:
		$ next = \text{stk.pop}\left(\right)$
		if $next$ is not None:
			print $next$
			stk.append$\left(next\left[\text{'leftchild'}\right]\right)$
			stk.append$\left(next\left[\text{'rightchild'}\right]\right)$
\end{lstlisting}



\section{Hash Tables}
\begin{xca*}
[11.1-2]\addcontentsline{toc}{subsection}{\numberline{}Exercise 11.1-2}
A \textbf{\emph{bit vector}} is simply an array of bits (0s and 1s).
A bit vector of length $m$ takes much less space than an array of
$m$ pointers. Describe how to use a bit vector to represent a dynamic
set of distinct elements with no satellite data. Dictionary operations
should run in $O\left(1\right)$ time.
\end{xca*}
\textbf{Solution}. Assign an index to each element. Use the bit vector
to indicate membership by settings bits by initializing all bits to
0 and then setting to 1 when inserting (deletion is reseting to 0).


\begin{xca*}
[11.1-3]\addcontentsline{toc}{subsection}{\numberline{}Exercise 11.1-3}
Suggest how to implement a direct-address table in which the keys
of stored el- ements do not need to be distinct and the elements can
have satellite data. All three dictionary operations ($\texttt{INSERT}$,
$\texttt{DELETE}$, and $\texttt{SEARCH}$ ) should run in $O\left(1\right)$
time. Don\textquoteright t forget that $\texttt{DELETE}$ takes as
an argument a pointer to an object to be deleted, not a key.
\end{xca*}
\textbf{Solution}. Use chaining. For $\texttt{DELETE}$ set the pointer
to a $\texttt{NULL}$.


\begin{xca*}
[11.1-4]\addcontentsline{toc}{subsection}{\numberline{}Exercise 11.1-4}
We wish to implement a dictionary by using direct addressing on a
huge array. At the start, the array entries may contain garbage, and
initializing the entire array is impractical because of its size.
Describe a scheme for implementing a direct-address dictionary on
a huge array. Each stored object should use $O\left(1\right)$ space;
the operations $\texttt{INSERT}$, $\texttt{DELETE}$, and $\texttt{SEARCH}$
should take $O\left(1\right)$ time each; and initializing the data
structure should take $O\left(1\right)$ time. Hint: Use an additional
array, treated somewhat like a stack whose size is the number of keys
actually stored in the dictionary, to help determine whether a given
entry in the huge array is valid or not.
\end{xca*}
\textbf{Solution}. Use the stack to store the actual values. Let $huge$
be the array and $stack$ be the stack. To insert an element with
key $x$ append $x$ to the stack and store in $huge\left[x\right]$
the length of the stack (i.e. the index of $x$ in the stack). To
search for an element $y$ (i.e. verify membership) check that $huge\left[y\right]\leq\texttt{len}\left(stack\right)$
and that $stack\left[huge\left[y\right]\right]=y$. To delete an element
$x$ swap the top of the stack with the element to be deleted and
update relevant entries in $huge$: 
\begin{eqnarray*}
stack\left[huge\left[x\right]\right] & = & stack\left[-1\right]\\
huge\left[stack\left[-1\right]\right] & = & huge\left[x\right]\\
huge\left[x\right] & = & \texttt{None}
\end{eqnarray*}
and pop the stack.


\begin{xca*}
[11.2-5]\addcontentsline{toc}{subsection}{\numberline{}Exercise 11.2-5}
Suppose that we are storing a set of $n$ keys into a hash table of
size $m$. Show that if the keys are drawn from a universe $U$ with
$\left|U\right|>nm$, then $U$ has a subset of size $n$ consisting
of keys that all hash to the same slot, so that the worst-case searching
time for hashing with chaining $\Theta\left(n\right)$.
\end{xca*}
\textbf{Solution}. Pigeonhole principle.


\begin{xca*}
[11.2-6]\addcontentsline{toc}{subsection}{\numberline{}Exercise 11.2-6}
Suppose we have stored $n$ keys in a hash table of size $m$, with
collisions resolved by chaining, and that we know the length of each
chain, including the length $L$ of the longest chain. Describe a
procedure that selects a key uniformly at random from among the keys
in the hash table and returns it in expected time $O\left(L\cdot\left(1+1/\alpha\right)\right)$,
where $\alpha=n/m$.
\end{xca*}
\textbf{Solution}. The keyword being randomly (not just any). Pick
a random bucket, which will have $k$ elements, then pick an index
$i$ from $i,\dots,L$. Reject if $i>k$ and draw $i$ again. This
is essentially rejection sampling the array, i.e. how to uniformly
random pick an element from $1,\dots,k$ if you can only generate
random numbers from 1 to $L$. The expected number of elements $k$
is equal to the load and so 
\[
P\left(i\leq k\right)=\frac{(n/m)}{L}
\]
and hence expected number of times before success is 
\[
\frac{1}{\frac{(n/m)}{L}}=\frac{L\cdot m}{n}
\]
(since ``success'' is a geometric random variable with probability
of success being $P\left(i\leq k\right)$). Picking the initial bucket
doesn't \textquotedbl{}cost\textquotedbl{} anything, hence combined
with time $L$ to traverse we get
\[
O\left(L+L\frac{m}{n}\right)=O\left(L\cdot\left(1+\frac{1}{\alpha}\right)\right)
\]
expected running time.


\section{Binary Search Trees}
\begin{xca*}
[12.1-2]\addcontentsline{toc}{subsection}{\numberline{}Exercise 12.1-2}
What is the difference between the binary-search-tree property and
the min-heap property? 
\end{xca*}
\textbf{Solution}. The min-heap property says parents should be larger
than both of its children, while the binary-search property says greater
than left-child but not right-child. 


\begin{xca*}
[12.1-3]\addcontentsline{toc}{subsection}{\numberline{}Exercise 12.1-3}Give
a nonrecursive algorithm that performs an inorder tree walk. (Hint:
An easy solution uses a stack as an auxiliary data structure. A more
complicated, but elegant, solution uses no stack but assumes that
we can test two pointers for equality.)
\end{xca*}
\textbf{Solution}. Both implementations are annoying as hell (and
disagree that the stack-less form is the least bit elegent). 

For the implementation with the stack the thing to remember is that
only none-$\texttt{None}$ nodes should get pushed to the stack and
a pointer should be used to keep track of which node we're actually
on. Also since we're using both the stack and the pointer to keep
track of things, the loop invariant is that either one (not necessarily
both) are not $\texttt{None}$\@.

\begin{lstlisting}[language=Python,numbers=left,basicstyle={\ttfamily},showstringspaces=false,tabsize=3,mathescape=true,frame=single,xleftmargin={.2\textwidth},xrightmargin={.2\textwidth}]
In-Order-Stack$\left(T\right)$
	$stk = \left[~\right]$
	$crnt = T$
	while $crnt$ or $\text{len}\left(stk\right) > 0$:
		if $crnt$:
			# push the last node that's 
			# legit
			$stk\text{.append}\left(crnt\right)$
			$crnt = crnt\left[\text{'lchild'}\right]$
		# crnt == None so the last node 
		# on the stack has no left child
		else: # len(stk) > 0
			$p = stk\text{.pop}\left(\right)$
			print $p\text{.val}$
			$crnt = p\left[\text{'rchild'}\right]$
\end{lstlisting}


Fof the implementation without the stack you need parent pointers
in order (get it...) to be able to discover which child you're in.
Also don't forget the first thing you need to check is if you're coming
back up from the right child.

\begin{figure}[H]
\begin{lstlisting}[language=Python,numbers=left,basicstyle={\ttfamily},showstringspaces=false,tabsize=3,mathescape=true,frame=single,xleftmargin={.1\textwidth},xrightmargin={.1\textwidth}]
In-Order-No-Stack$\left(T\right)$
	$prev = crnt = T$
	while True:
		$prev = crnt$
		if $prev == crnt\left[\text{'rchild'}\right]$:
			# come back up from the
			# right child
			if $crnt\left[\text{'prnt'}\right] \neq \text{None}$:
				$crnt = crnt\left[\text{'prnt'}\right]$
			else:
				break
		elif $crnt\left[\text{'lchild'}\right] == \text{None}$ or $prev == crnt\left[\text{'lchild'}\right]$:
			print $crnt\text{.val}$
			if $crnt\left[\text{'rchild'}\right] \neq \text{None}$:
				$crnt = crnt\left[\text{'rchild'}\right]$
			elif $crnt\left[\text{'prnt'}\right] \neq \text{None}$:
				$crnt = crnt\left[\text{'prnt'}\right]$
			else:
				break
		else:
			$crnt = crnt\left[\text{'lchild'}\right]$
\end{lstlisting}
\end{figure}



\begin{xca*}
[12.1-4]\addcontentsline{toc}{subsection}{\numberline{}Exercise 12.1-4}Give
recursive algorithms that perform preorder and postorder tree walks
in $\Theta\left(n\right)$ time on a tree of $n$ nodes.
\end{xca*}
\textbf{Solution}. Recursive implementations are easy; iterative implementations
are hard. I'll just comment on how these differ from $\texttt{In-Order-Stack}$
(for stack-less it's obvious): to perform an Pre-Order traversal move
the print statement into the first branch of the conditional (before
reassigning $crnt$). Printing out a Post-Order traversal is actually
easy: just use $\texttt{DFS}$ from 10.4-3 and reverse the order.


\begin{xca*}
[12.2-2]\addcontentsline{toc}{subsection}{\numberline{}Exercise 12.2-2}
Write recursive versions of $\texttt{TREE-MINIMUM}$ and $\texttt{TREE-MAXIMUM}$.
\end{xca*}
\textbf{Solution}. I have no idea why you would insist on a recursive
implementation of both of these since they're easily implemented iteratively.

\begin{lstlisting}[language=Python,numbers=left,basicstyle={\ttfamily},showstringspaces=false,tabsize=3,mathescape=true,frame=single,xleftmargin={.2\textwidth},xrightmargin={.2\textwidth}]
Tree-Min$\left(T\right)$
	$ptr =T$
	while $ptr\left[\text{'lchild'}\right]$:
		$ptr = ptr\left[\text{'lchild'}\right]$
	return $ptr$
\end{lstlisting}


\begin{lstlisting}[language=Python,numbers=left,basicstyle={\ttfamily},showstringspaces=false,tabsize=3,mathescape=true,frame=single,xleftmargin={.2\textwidth},xrightmargin={.2\textwidth}]
Tree-Max$\left(T\right)$
	$ptr =T$
	while $ptr\left[\text{'rchild'}\right]$:
		$ptr = ptr\left[\text{'rchild'}\right]$
	return $ptr$
\end{lstlisting}



\begin{xca*}
[12.2-3]\addcontentsline{toc}{subsection}{\numberline{}Exercise 12.2-3}
Write the $\texttt{TREE-PREDECESSOR}$ procedure.
\end{xca*}
\textbf{Solution}. If a node's left-subtree exists then the node's
predecessor is the maximum of that subtree. If the node's subtree
doesn't exist then the node's predecessor is ``on top'' of it: it's
the ``lowest'' ancestor of the node whose right child is also an
ancestor of the node. Basically go up and cut the first left that
you can.

\begin{figure}[H]
\begin{lstlisting}[language=Python,numbers=left,basicstyle={\ttfamily},showstringspaces=false,tabsize=3,mathescape=true,frame=single,xleftmargin={.2\textwidth},xrightmargin={.2\textwidth}]
Predecessor$\left(x\right)$
	# assume $x$ is a pointer to the node
	# (which could be found by a search)
	if $x\left['lchild'\right]$:
		return Tree-Max$\left(x\left['lchild'\right]\right)$
	else:
		$ptr = x$
		$prnt = x\left['prnt'\right]$
		# while you haven't cut a left
		while $ptr$ and $ptr == prnt\left['lchild'\right]$:
			$ptr = prnt$
			$prnt = ptr\left['prnt'\right]$
		return $prnt$
\end{lstlisting}
\end{figure}
Just for completeness note that successor is symmetric: either minimum
of the right-subtree or go up and cut a right.


\end{document}
